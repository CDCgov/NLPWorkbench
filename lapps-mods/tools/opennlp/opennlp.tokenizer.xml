<tool id="opennlp.tokenizer" name="OpenNLP Tokenizer" version="2.0.3">
 <command interpreter="lsd">
  ../common/invoke_brandeis.lsd opennlp.tokenizer_2.0.3 $input $output
 </command>
 <inputs>
  <param format="lif,json" label="input" name="input" type="data">
  </param>
 </inputs>
 <outputs>
  <data format="lif" name="output">
  </data>
 </outputs>
 <help>
  <![CDATA[
**What it does** 
  
Splits text into simple tokens such as numbers, punctuation, and words using 
the `OpenNLP <https://opennlp.apache.org>`_ TokenizerME (see the `OpenNLP Tokenization Tutorial <https://www.tutorialspoint.com/opennlp/opennlp_tokenization.htm>`_ for more information).
This tokenizer uses Maximum Entropy to make its decisions, which reproduces the tokenization 
observed in the training data used to create the model.

**Required annotations**

* None

.. class:: infomark

This tokenizer processes plain text in a LIF container.
It can also process a LIF document containing  `Sentence <http://vocab.lappsgrid.org/Sentence.html>`_ annotations.

.. class:: infomark

**TIP**: If you want to input plain text and it is not not wrapped in a LIF container, use *Convert Formats->Wrap text*

**Generated Annotations**

* A LIF document with a new view containing `Token <http://vocab.lappsgrid.org/Token.html>`_ annotations 

**License**

Apache OpenNLP is licensed under the `Apache License, Version 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_

]]>
 </help>
</tool>
